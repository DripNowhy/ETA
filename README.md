<div align="center">
    <img src="assets/ETA.svg" alt="ETA Logo" width="256px">
<p>Generated by <a href="https://openai.com/dall-e-3">DALL·E</a></p>
</div>

<div align="center">

<!-- # ETA -->

# ETA: Evaluating Then Aligning Safety of Vision Language Models at Inference-Time

</div>

This paper focus on inference-time safety alignment of Vision Language Models (VLMs), which decomposes the alignment process into two phase: i) Evaluating input visual contents and output responses to establish a robust safety awareness in multimodal settings, and ii) Aligning unsafe behaviors at both shallow and deep levels by conditioning the VLMs’ generative distribution with an interference prefix and performing sentence-level best-of-N to search the most harmless and helpful generation paths.

<div align="center">
    <img src="assets/ETA.pdf" alt="ETA Framework">
</div>
